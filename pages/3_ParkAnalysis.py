import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import folium
from streamlit_folium import st_folium
from utils import set_korean_font, load_csv, load_geojson # utils.pyì˜ í•¨ìˆ˜ ì„í¬íŠ¸
import os
import numpy as np
from shapely.geometry import shape # ì¤‘ì‹¬ì  ê³„ì‚°ì„ ìœ„í•´ ì¶”ê°€

# --- ë°ì´í„° ì „ì²˜ë¦¬ ë° ì¶”ì¶œ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---
@st.cache_data
def preprocess_park_data_cached(df_raw):
    if df_raw is None:
        st.error("preprocess_park_data_cached: ì›ë³¸ ë°ì´í„°ê°€ Noneì…ë‹ˆë‹¤.")
        return pd.DataFrame(), pd.DataFrame()

    df_processed = df_raw.copy()
    gu_column_tuple = None
    if len(df_processed.columns) > 1:
        potential_gu_column_tuple = df_processed.columns[1]
        gu_column_tuple = potential_gu_column_tuple
    else:
        st.error("ê³µì› ë°ì´í„°ì˜ ì»¬ëŸ¼ ìˆ˜ê°€ 2ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤. ìì¹˜êµ¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(), pd.DataFrame()

    try:
        df_processed = df_processed.set_index(gu_column_tuple)
        df_processed.index.name = 'ìì¹˜êµ¬'
        if len(df_raw.columns) > 0:
            first_column_tuple_to_drop = df_raw.columns[0]
            if first_column_tuple_to_drop in df_processed.columns:
                 df_processed = df_processed.drop(columns=[first_column_tuple_to_drop])
    except KeyError as e:
        st.error(f"ê³µì› ë°ì´í„° ì¸ë±ìŠ¤ ì„¤ì • ì¤‘ KeyError: {e}. ì»¬ëŸ¼ëª…: {gu_column_tuple}")
        return pd.DataFrame(), pd.DataFrame()
    except Exception as e:
        st.error(f"ê³µì› ë°ì´í„° ì¸ë±ìŠ¤ ì„¤ì • ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}")
        return pd.DataFrame(), pd.DataFrame()

    df_seoul_total = pd.DataFrame()
    if 'ì†Œê³„' in df_processed.index:
        df_seoul_total = df_processed.loc[['ì†Œê³„']].copy()
    else:
        st.warning("ê°€ê³µëœ ê³µì› ë°ì´í„°ì—ì„œ 'ì†Œê³„'(ì„œìš¸ì‹œ ì „ì²´ í•©ê³„) í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    districts_to_exclude = ['ì†Œê³„', 'ì„œìš¸ëŒ€ê³µì›']
    districts_df = df_processed.drop(index=districts_to_exclude, errors='ignore')

    if districts_df.empty:
        st.warning("ìì¹˜êµ¬ë³„ ê³µì› ë°ì´í„°(districts_df)ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    return districts_df, df_seoul_total

@st.cache_data
def extract_total_park_stats_cached(districts_df, years_str_list):
    if districts_df is None or districts_df.empty:
        return pd.DataFrame(), pd.DataFrame()

    park_counts_list = []
    park_areas_list = []

    for district_name in districts_df.index:
        try:
            district_data_series = districts_df.loc[district_name]
        except KeyError:
            st.warning(f"'{district_name}' ìì¹˜êµ¬ ë°ì´í„°ë¥¼ districts_dfì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        counts = {'ìì¹˜êµ¬': district_name}
        areas = {'ìì¹˜êµ¬': district_name}

        for year_str in years_str_list:
            count_col_tuple = (year_str, 'í•©ê³„', 'ì†Œê³„', 'ì†Œê³„', 'ê³µì›ìˆ˜ (ê°œì†Œ)')
            area_col_tuple = (year_str, 'í•©ê³„', 'ì†Œê³„', 'ì†Œê³„', 'ë©´ì  (ì²œã¡)')

            count_val = district_data_series.get(count_col_tuple)
            area_val = district_data_series.get(area_col_tuple)

            counts[year_str] = pd.to_numeric(count_val, errors='coerce')
            areas[year_str] = pd.to_numeric(area_val, errors='coerce')

        park_counts_list.append(counts)
        park_areas_list.append(areas)

    df_park_counts = pd.DataFrame(park_counts_list)
    if not df_park_counts.empty:
        df_park_counts = df_park_counts.set_index('ìì¹˜êµ¬').fillna(0)
        df_park_counts = df_park_counts[[col for col in years_str_list if col in df_park_counts.columns]]

    df_park_area = pd.DataFrame(park_areas_list)
    if not df_park_area.empty:
        df_park_area = df_park_area.set_index('ìì¹˜êµ¬').fillna(0)
        df_park_area = df_park_area[[col for col in years_str_list if col in df_park_area.columns]]

    return df_park_counts, df_park_area

# --- ì‹œê°í™” í•¨ìˆ˜ ---
def plot_yearly_district_comparison(df_metric, metric_name, unit, selected_year_str, bar_color='skyblue'):
    if df_metric.empty or selected_year_str not in df_metric.columns:
        st.info(f"{selected_year_str}ë…„ {metric_name} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    data_for_year = df_metric[[selected_year_str]].sort_values(by=selected_year_str, ascending=False).reset_index()
    if data_for_year.empty:
        st.info(f"{selected_year_str}ë…„ ì •ë ¬ í›„ {metric_name} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    fig, ax = plt.subplots(figsize=(10, 12))
    sns.barplot(x=selected_year_str, y='ìì¹˜êµ¬', data=data_for_year, color=bar_color, ax=ax)
    ax.set_title(f'{selected_year_str}ë…„ ìì¹˜êµ¬ë³„ ì´ ê³µì› {metric_name}', fontsize=16)
    ax.set_xlabel(f'ì´ ê³µì› {metric_name} ({unit})', fontsize=12)
    ax.set_ylabel('ìì¹˜êµ¬', fontsize=12)
    ax.tick_params(axis='x', labelsize=10); ax.tick_params(axis='y', labelsize=9)
    for index, value in enumerate(data_for_year[selected_year_str]):
        if pd.notna(value) and value > 0:
            formatted_value = f'{value:,.1f}' if isinstance(value, float) and unit == "ì²œã¡" else f'{int(value):,}'
            ax.text(value, index, f' {formatted_value}', va='center', ha='left', fontsize=8, color='black')
    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))
    plt.tight_layout(); st.pyplot(fig)

def plot_seoul_total_distribution(df_seoul_total, selected_year_str):
    if df_seoul_total is None or df_seoul_total.empty:
        st.info(f"{selected_year_str}ë…„ ì„œìš¸ì‹œ ì „ì²´ ê³µì› ìœ í˜•ë³„ ë©´ì  ë°ì´í„°ê°€ ì—†ì–´ íŒŒì´ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    if 'ì†Œê³„' not in df_seoul_total.index:
        st.warning("plot_seoul_total_distribution: 'ì†Œê³„' ì¸ë±ìŠ¤ë¥¼ ê°€ì§„ ì„œìš¸ì‹œ ì „ì²´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    seoul_total_row_data = df_seoul_total.loc['ì†Œê³„']
    park_type_areas = {}
    urban_facility_park_types = ['ê·¼ë¦°ê³µì›', 'ì–´ë¦°ì´ê³µì›', 'ì†Œê³µì›', 'ë¬˜ì§€ê³µì›', 'ë¬¸í™”ê³µì›', 'ì²´ìœ¡ê³µì›', 'ì—­ì‚¬ê³µì›', 'ìˆ˜ë³€ê³µì›', 'ìƒíƒœê³µì›', 'ê°€ë¡œê³µì›']
    for park_type in urban_facility_park_types:
        col_name = (selected_year_str, 'ë„ì‹œê³µì›', 'ë„ì‹œê³„íšì‹œì„¤(ê³µì›) ', park_type, 'ë©´ì  (ì²œã¡)')
        area = pd.to_numeric(seoul_total_row_data.get(col_name), errors='coerce')
        if pd.notna(area) and area > 0: park_type_areas[park_type] = area
    col_name_natural = (selected_year_str, 'ë„ì‹œê³µì›', 'ë„ì‹œìì—°ê³µì›êµ¬ì—­', 'ì†Œê³„', 'ë©´ì  (ì²œã¡)')
    area_dz = pd.to_numeric(seoul_total_row_data.get(col_name_natural), errors='coerce')
    if pd.notna(area_dz) and area_dz > 0: park_type_areas['ë„ì‹œìì—°ê³µì›êµ¬ì—­'] = area_dz

    if not park_type_areas:
        st.info(f"{selected_year_str}ë…„ ì„œìš¸ì‹œ ì „ì²´ ê³µì› ìœ í˜•ë³„ ë©´ì  ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.")
        return

    park_types_series = pd.Series(park_type_areas).sort_values(ascending=False)

    # ì‘ì€ ë¹„ìœ¨ì˜ í•­ëª©ë“¤ì„ 'ê¸°íƒ€'ë¡œ ë¬¶ê¸°
    threshold_ratio = 2.0 # 2% ë¯¸ë§Œì€ 'ê¸°íƒ€'ë¡œ (ì¡°ì • ê°€ëŠ¥)
    total_area = park_types_series.sum()
    small_slices = park_types_series[park_types_series / total_area * 100 < threshold_ratio]
    
    if not small_slices.empty and len(park_types_series) > len(small_slices) and len(small_slices) > 1 : # 'ê¸°íƒ€'ë¡œ ë¬¶ì„ í•­ëª©ì´ 2ê°œ ì´ìƒì´ê³ , ëª¨ë“  í•­ëª©ì´ ì‘ì€ ì¡°ê°ì€ ì•„ë‹Œ ê²½ìš°
        other_sum = small_slices.sum()
        park_types_series_major = park_types_series[park_types_series / total_area * 100 >= threshold_ratio]
        if other_sum > 0:
            park_types_series_major['ê¸°íƒ€'] = other_sum
        park_types_series_to_plot = park_types_series_major.sort_values(ascending=False)
    else:
        park_types_series_to_plot = park_types_series

    num_slices = len(park_types_series_to_plot)
    explode = [0.0] * num_slices
    if num_slices > 2 : 
        if 'ê¸°íƒ€' in park_types_series_to_plot.index:
            explode[park_types_series_to_plot.index.get_loc('ê¸°íƒ€')] = 0.05
        else:
            if num_slices > 3: # ì‘ì€ ì¡°ê°ì´ ì—¬ëŸ¬ ê°œ ìˆì„ ê²½ìš° ì•½ê°„ì”© ë–¼ì–´ëƒ„
                 explode[-1] = 0.05 
                 explode[-2] = 0.03


    fig, ax = plt.subplots(figsize=(13, 10)) # figsize ì¡°ì •

    def autopct_format(pct):
        # ì‘ì€ ë¹„ìœ¨ì˜ ë ˆì´ë¸”ì€ í¼ì„¼íŠ¸ë§Œ í‘œì‹œí•˜ê±°ë‚˜ í‘œì‹œí•˜ì§€ ì•Šë„ë¡ ì¡°ì •
        return f'{pct:.1f}%' if pct >= 2.5 else '' # 2.5% ì´ìƒë§Œ í¼ì„¼íŠ¸ í‘œì‹œ (ì¡°ì • ê°€ëŠ¥)

    patches, texts, autotexts = ax.pie(
        park_types_series_to_plot,
        labels=park_types_series_to_plot.index,
        autopct=autopct_format, 
        startangle=140,
        pctdistance=0.85, # í¼ì„¼íŠ¸ í…ìŠ¤íŠ¸ ìœ„ì¹˜
        labeldistance=1.05, # ë ˆì´ë¸” í…ìŠ¤íŠ¸ ìœ„ì¹˜
        wedgeprops={'edgecolor': 'white', 'linewidth': 1},
        explode=explode 
    )

    for text in texts:
        text.set_fontsize(9) 
    for autotext in autotexts:
        autotext.set_fontsize(8) 
        autotext.set_color('black')

    ax.set_title(f'ì„œìš¸ì‹œ ë„ì‹œê³µì› ìœ í˜•ë³„ ë©´ì  ë¶„í¬ ({selected_year_str}ë…„)', fontsize=16)
    ax.axis('equal')
    plt.tight_layout()
    st.pyplot(fig)

def create_choropleth_map(df_metric, geo_data, year_str, metric_name, unit, fill_color_map='Blues'):
    if df_metric.empty or year_str not in df_metric.columns:
        st.info(f"{year_str}ë…„ {metric_name} ì§€ë„ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    data_to_map = df_metric[[year_str]].copy()
    if data_to_map.index.name != 'ìì¹˜êµ¬':
        st.warning("create_choropleth_map: ì§€ë„ìš© ë°ì´í„°ì˜ ì¸ë±ìŠ¤ê°€ 'ìì¹˜êµ¬'ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        return None

    m = folium.Map(location=[37.5665, 126.9780], zoom_start=10.5, tiles='CartoDB positron')

    if geo_data:
        try:
            choropleth_layer = folium.Choropleth(
                geo_data=geo_data,
                data=data_to_map.reset_index(),
                columns=['ìì¹˜êµ¬', year_str],
                key_on='feature.properties.name',
                fill_color=fill_color_map,
                fill_opacity=0.7,
                line_opacity=0.3,
                legend_name=f'{year_str}ë…„ {metric_name} ({unit})',
                highlight=True,
                name=f'{year_str}ë…„ {metric_name}'
            ).add_to(m)

            for feature in choropleth_layer.geojson.data['features']:
                gu_name_geojson = feature['properties'].get('name')
                if not gu_name_geojson:
                    continue
                try:
                    geom = shape(feature['geometry'])
                    center_point = geom.centroid
                    center_lon, center_lat = center_point.x, center_point.y
                except Exception:
                    continue

                folium.Marker(
                    location=[center_lat, center_lon],
                    icon=folium.DivIcon(
                        html=f'<div style="font-size: 9pt; font-weight: bold; color: black; background-color: transparent; white-space: nowrap;">{gu_name_geojson}</div>'
                    )
                ).add_to(m)
            return m
        except Exception as e:
            st.error(f"Folium ì§€ë„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    else:
        st.warning("GeoJSON ë°ì´í„°ê°€ ì—†ì–´ ì§€ë„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

# --- Streamlit í˜ì´ì§€ êµ¬ì„± ---
def run_park_analysis_page():
    st.title("ğŸŒ³ ì„œìš¸ì‹œ ê³µì› ë¶„ì„")
    set_korean_font()

    park_years_int = [2019, 2020, 2021, 2022, 2023]
    park_years_str = [str(y) for y in park_years_int]

    if "selected_year_park" not in st.session_state:
        st.session_state.selected_year_park = park_years_int[-1]

    selected_year_int = st.slider(
        "ì¡°íšŒ ì—°ë„ ì„ íƒ",
        min_value=park_years_int[0],
        max_value=park_years_int[-1],
        step=1,
        value=st.session_state.selected_year_park,
        key="park_year_slider_main"
    )
    st.session_state.selected_year_park = selected_year_int
    selected_year_str = str(selected_year_int)

    df_raw_parks = load_csv("data/ê³µì›_20250525010638.csv", header_config=[0,1,2,3,4], na_values_config='-')
    if df_raw_parks is None:
        st.error("ê³µì› ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'data/ê³µì›_20250525010638.csv' íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    districts_df_parks, df_seoul_total_parks = preprocess_park_data_cached(df_raw_parks)
    if districts_df_parks is None or districts_df_parks.empty:
        st.error("ê³µì› ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆê±°ë‚˜, ìœ íš¨í•œ ìì¹˜êµ¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_park_counts, df_park_area = extract_total_park_stats_cached(districts_df_parks, park_years_str)

    geojson_url = 'https://raw.githubusercontent.com/southkorea/seoul-maps/master/kostat/2013/json/seoul_municipalities_geo_simple.json'
    @st.cache_data
    def get_geojson_cached_park_page(url): return load_geojson(url)
    seoul_geo_data_parks = get_geojson_cached_park_page(geojson_url)

    tab1, tab2, tab3 = st.tabs([
        "ğŸ“Š ì—°ë„ë³„ ìì¹˜êµ¬ í˜„í™©",
        "ğŸ“ˆ ì„œìš¸ì‹œ ì „ì²´ í˜„í™©",
        "ğŸ—ºï¸ ì§€ë„ ì‹œê°í™”"
    ])

    with tab1:
        st.subheader(f"{selected_year_str}ë…„ ìì¹˜êµ¬ë³„ ê³µì› í˜„í™©")
        st.markdown("##### ì´ ê³µì› ë©´ì  (ì²œã¡)")
        if not df_park_area.empty:
            plot_yearly_district_comparison(df_park_area, "ë©´ì ", "ì²œã¡", selected_year_str, bar_color='cornflowerblue')
        else: st.info("ìì¹˜êµ¬ë³„ ê³µì› ë©´ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("##### ì´ ê³µì› ìˆ˜ (ê°œì†Œ)")
        if not df_park_counts.empty:
            plot_yearly_district_comparison(df_park_counts, "ìˆ˜", "ê°œì†Œ", selected_year_str, bar_color='mediumseagreen')
        else: st.info("ìì¹˜êµ¬ë³„ ê³µì› ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("##### ê³µì› 1ê°œì†Œë‹¹ í‰ê·  ë©´ì  (ì²œã¡/ê°œì†Œ)")
        if not df_park_counts.empty and not df_park_area.empty:
            df_park_counts_for_avg = df_park_counts.replace(0, np.nan)
            if not df_park_counts_for_avg.empty and selected_year_str in df_park_counts_for_avg.columns:
                df_avg_park_area = df_park_area.div(df_park_counts_for_avg).fillna(0)
                plot_yearly_district_comparison(df_avg_park_area, "1ê°œì†Œë‹¹ í‰ê·  ë©´ì ", "ì²œã¡/ê°œì†Œ", selected_year_str, bar_color='lightcoral')
            else: st.info(f"{selected_year_str}ë…„ ê³µì› ìˆ˜ê°€ ëª¨ë‘ 0ì´ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ì–´ 1ê°œì†Œë‹¹ í‰ê·  ë©´ì ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else: st.info("ìì¹˜êµ¬ë³„ ê³µì› 1ê°œì†Œë‹¹ í‰ê·  ë©´ì ì„ ê³„ì‚°í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    with tab2:
        st.subheader(f"{selected_year_str}ë…„ ì„œìš¸ì‹œ ì „ì²´ ë„ì‹œê³µì› ìœ í˜•ë³„ ë©´ì  ë¶„í¬")
        plot_seoul_total_distribution(df_seoul_total_parks, selected_year_str)

    with tab3:
        st.subheader(f"{selected_year_str}ë…„ ê³µì› ì§€ë„ ì‹œê°í™”")
        map_metric_parks = st.selectbox("ì§€ë„ í‘œì‹œ í•­ëª© ì„ íƒ:", ["ì´ ê³µì› ìˆ˜", "ì´ ê³µì› ë©´ì ", "1ê°œì†Œë‹¹ í‰ê·  ë©´ì "], key="park_map_metric_sb_main_tab")

        if seoul_geo_data_parks:
            park_map_to_display = None
            if map_metric_parks == "ì´ ê³µì› ìˆ˜":
                if not df_park_counts.empty:
                    park_map_to_display = create_choropleth_map(df_park_counts, seoul_geo_data_parks, selected_year_str, "ì´ ê³µì› ìˆ˜", "ê°œì†Œ", "Greens")
                else: st.info("ì´ ê³µì› ìˆ˜ ë°ì´í„°ê°€ ì—†ì–´ ì§€ë„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            elif map_metric_parks == "ì´ ê³µì› ë©´ì ":
                if not df_park_area.empty:
                    park_map_to_display = create_choropleth_map(df_park_area, seoul_geo_data_parks, selected_year_str, "ì´ ê³µì› ë©´ì ", "ì²œã¡", "Blues")
                else: st.info("ì´ ê³µì› ë©´ì  ë°ì´í„°ê°€ ì—†ì–´ ì§€ë„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            elif map_metric_parks == "1ê°œì†Œë‹¹ í‰ê·  ë©´ì ":
                if not df_park_counts.empty and not df_park_area.empty:
                    df_park_counts_for_avg_map = df_park_counts.replace(0, np.nan)
                    if not df_park_counts_for_avg_map.empty and selected_year_str in df_park_counts_for_avg_map.columns:
                        df_avg_park_area_map = df_park_area.div(df_park_counts_for_avg_map).fillna(0)
                        park_map_to_display = create_choropleth_map(df_avg_park_area_map, seoul_geo_data_parks, selected_year_str, "1ê°œì†Œë‹¹ í‰ê·  ë©´ì ", "ì²œã¡/ê°œì†Œ", "Oranges")
                    else: st.info(f"{selected_year_str}ë…„ 1ê°œì†Œë‹¹ í‰ê·  ë©´ì ì„ ê³„ì‚°í•  ë°ì´í„°(ê³µì› ìˆ˜)ê°€ ì—†ì–´ ì§€ë„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else: st.info("1ê°œì†Œë‹¹ í‰ê·  ë©´ì  ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ì–´ ì§€ë„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            if park_map_to_display:
                st_folium(park_map_to_display, width=800, height=600)
            elif seoul_geo_data_parks :
                 st.info("ì„ íƒí•œ í•­ëª©ì— ëŒ€í•œ ì§€ë„ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("GeoJSON ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ì§€ë„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    run_park_analysis_page()
