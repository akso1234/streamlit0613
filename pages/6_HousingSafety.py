import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from utils import set_korean_font, load_csv
import os

# --- ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---
@st.cache_data
def preprocess_rescue_data_cached(df_rescue_raw):
    if df_rescue_raw is None: return pd.DataFrame()
    return df_rescue_raw.copy()

@st.cache_data
def preprocess_elderly_data_for_housing_cached(df_elderly_raw):
    if df_elderly_raw is None: return pd.DataFrame()
    df_elderly_processed = df_elderly_raw.copy()
    try:
        new_columns = [tuple(s.replace('"', '').strip() if isinstance(s, str) else s for s in ct) for ct in df_elderly_processed.columns]
        df_elderly_processed.columns = pd.MultiIndex.from_tuples(new_columns, names=df_elderly_processed.columns.names)
        target_pop_col_tuple = None
        for col_tuple in df_elderly_processed.columns:
            if len(col_tuple) == 4 and str(col_tuple[0]).strip().startswith('2023') and \
               '65ì„¸ì´ìƒ ì¸êµ¬' in str(col_tuple[1]).strip() and 'ì†Œê³„' == str(col_tuple[2]).strip() and 'ì†Œê³„' == str(col_tuple[3]).strip():
                target_pop_col_tuple = col_tuple; break
        if target_pop_col_tuple is None:
            if len(df_elderly_processed.columns) > 55:
                potential_col = df_elderly_processed.columns[55]
                if isinstance(potential_col, tuple) and len(potential_col) == 4 and \
                   str(potential_col[0]).strip().startswith('2023') and '65ì„¸ì´ìƒ ì¸êµ¬' in str(potential_col[1]).strip() and \
                   'ì†Œê³„' == str(potential_col[2]).strip() and 'ì†Œê³„' == str(potential_col[3]).strip():
                    target_pop_col_tuple = potential_col
            if target_pop_col_tuple is None: st.error("ê³ ë ¹ìí˜„í™©: ì¸êµ¬ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•¨."); return pd.DataFrame()

        if len(df_elderly_processed.columns) < 2: st.error("ê³ ë ¹ìí˜„í™©: ìì¹˜êµ¬ ì •ë³´ ì»¬ëŸ¼ ë¶€ì¡±."); return pd.DataFrame()
        gu_info_col_tuple_elderly = df_elderly_processed.columns[1]
        df_filtered_elderly = df_elderly_processed[df_elderly_processed[gu_info_col_tuple_elderly].astype(str).str.strip() != 'ì†Œê³„'].copy()
        if gu_info_col_tuple_elderly in df_filtered_elderly.columns and target_pop_col_tuple in df_filtered_elderly.columns:
            df_final_elderly = df_filtered_elderly[[gu_info_col_tuple_elderly, target_pop_col_tuple]].copy()
            df_final_elderly.columns = ['ë°œìƒì¥ì†Œ_êµ¬', 'ë…¸ì¸ì¸êµ¬ìˆ˜']
            df_final_elderly['ë°œìƒì¥ì†Œ_êµ¬'] = df_final_elderly['ë°œìƒì¥ì†Œ_êµ¬'].astype(str).str.strip()
            df_final_elderly['ë…¸ì¸ì¸êµ¬ìˆ˜'] = pd.to_numeric(df_final_elderly['ë…¸ì¸ì¸êµ¬ìˆ˜'], errors='coerce')
            df_final_elderly.dropna(subset=['ë°œìƒì¥ì†Œ_êµ¬', 'ë…¸ì¸ì¸êµ¬ìˆ˜'], inplace=True)
            return df_final_elderly
        else: return pd.DataFrame()
    except Exception as e: st.error(f"ê³ ë ¹ìí˜„í™© ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {e}"); return pd.DataFrame()

@st.cache_data
def preprocess_housing_data_cached(df_housing_raw):
    if df_housing_raw is None: return pd.DataFrame()
    df_housing_processed = df_housing_raw.copy()
    try:
        new_cols_h = [tuple(str(l).replace('"', '').strip() if isinstance(l,str) else l for l in ct) for ct in df_housing_processed.columns]
        df_housing_processed.columns = pd.MultiIndex.from_tuples(new_cols_h, names=df_housing_processed.columns.names)
        target_housing_col_tuple = None
        for col_tuple_h in df_housing_processed.columns:
            if len(col_tuple_h) == 3 and (str(col_tuple_h[1]).strip() in ["30ë…„ì´ìƒ", "30ë…„ ì´ìƒ"]) and str(col_tuple_h[2]).strip() == "ê³„":
                target_housing_col_tuple = col_tuple_h; break
        if target_housing_col_tuple is None: st.error("ë…¸í›„ ì£¼íƒ ë°ì´í„°: '30ë…„ ì´ìƒ ê³„' ì»¬ëŸ¼ ëª» ì°¾ìŒ."); return pd.DataFrame()
        if len(df_housing_processed.columns) < 2: st.error("ë…¸í›„ ì£¼íƒ ë°ì´í„°: ìì¹˜êµ¬ ì •ë³´ ì»¬ëŸ¼ ë¶€ì¡±."); return pd.DataFrame()
        gu_info_col_tuple_housing = df_housing_processed.columns[1]
        df_filtered_housing = df_housing_processed[df_housing_processed[gu_info_col_tuple_housing].astype(str).str.strip() != 'ì†Œê³„'].copy()
        if gu_info_col_tuple_housing in df_filtered_housing.columns and target_housing_col_tuple in df_filtered_housing.columns:
            df_final_housing = df_filtered_housing[[gu_info_col_tuple_housing, target_housing_col_tuple]].copy()
            df_final_housing.columns = ['ë°œìƒì¥ì†Œ_êµ¬', 'ë…¸í›„ì£¼íƒìˆ˜']
            df_final_housing['ë°œìƒì¥ì†Œ_êµ¬'] = df_final_housing['ë°œìƒì¥ì†Œ_êµ¬'].astype(str).str.strip()
            df_final_housing['ë…¸í›„ì£¼íƒìˆ˜'] = pd.to_numeric(df_final_housing['ë…¸í›„ì£¼íƒìˆ˜'], errors='coerce')
            df_final_housing.dropna(subset=['ë°œìƒì¥ì†Œ_êµ¬', 'ë…¸í›„ì£¼íƒìˆ˜'], inplace=True)
            return df_final_housing
        else: return pd.DataFrame()
    except Exception as e: st.error(f"ë…¸í›„ ì£¼íƒ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {e}"); return pd.DataFrame()

# --- ì‹œê°í™” í•¨ìˆ˜ (ìƒ‰ìƒ í†µì¼) ---
def plot_gu_incident_counts(df_rescue):
    if df_rescue.empty or 'ë°œìƒì¥ì†Œ_êµ¬' not in df_rescue.columns: st.info("êµ¬ë³„ ì´ ì‚¬ê³  ë°œìƒ ê±´ìˆ˜ ë°ì´í„°ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return
    gu_incident_counts = df_rescue['ë°œìƒì¥ì†Œ_êµ¬'].value_counts().sort_values(ascending=False)
    fig, ax = plt.subplots(figsize=(12, 7))
    sns.barplot(x=gu_incident_counts.index, y=gu_incident_counts.values, color='steelblue', ax=ax)
    ax.set_title('ì„œìš¸ì‹œ êµ¬ë³„ ì´ ì‚¬ê³  ë°œìƒ ê±´ìˆ˜', fontsize=16); ax.set_xlabel('ìì¹˜êµ¬', fontsize=12); ax.set_ylabel('ì‚¬ê³  ê±´ìˆ˜', fontsize=12)
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right", fontsize=10); ax.tick_params(axis='y', labelsize=10)
    ax.grid(axis='y', linestyle='--', alpha=0.7); ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))
    plt.tight_layout(); st.pyplot(fig)

def plot_stacked_bar_incident_causes_by_gu(df_rescue, top_n_causes=7):
    if df_rescue.empty or 'ë°œìƒì¥ì†Œ_êµ¬' not in df_rescue.columns or 'ì‚¬ê³ ì›ì¸' not in df_rescue.columns: st.info("êµ¬ë³„ ì‚¬ê³ ì›ì¸ë³„ ë°œìƒ ê±´ìˆ˜ ë°ì´í„°ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return
    gu_cause_counts = df_rescue.groupby(['ë°œìƒì¥ì†Œ_êµ¬', 'ì‚¬ê³ ì›ì¸']).size().unstack(fill_value=0)
    gu_cause_counts['ì´ê³„'] = gu_cause_counts.sum(axis=1)
    gu_cause_counts = gu_cause_counts.sort_values(by='ì´ê³„', ascending=False).drop(columns='ì´ê³„')
    if gu_cause_counts.shape[1] > top_n_causes:
        top_causes_sum = gu_cause_counts.sum(axis=0).nlargest(top_n_causes).index
        df_plot = gu_cause_counts[top_causes_sum].copy()
        df_plot['ê¸°íƒ€ì›ì¸'] = gu_cause_counts.drop(columns=top_causes_sum).sum(axis=1)
    else:
        df_plot = gu_cause_counts.copy()
        if 'ê¸°íƒ€ì›ì¸' not in df_plot.columns and df_plot.shape[1] > 0 : df_plot['ê¸°íƒ€ì›ì¸'] = 0
    if df_plot.empty: st.info("ì‚¬ê³  ì›ì¸ë³„ ì§‘ê³„ ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ ëˆ„ì  ë§‰ëŒ€ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return
    fig, ax = plt.subplots(figsize=(18, 10))
    df_plot.plot(kind='bar', stacked=True, ax=ax) # colormap ì œê±°
    ax.set_title(f'ì„œìš¸ì‹œ êµ¬ë³„ ì£¼ìš” ì‚¬ê³ ì›ì¸ë³„ ë°œìƒ ê±´ìˆ˜ (ìƒìœ„ {top_n_causes}ê°œ ë° ê¸°íƒ€)', fontsize=16, pad=15)
    ax.set_xlabel('ìì¹˜êµ¬', fontsize=12); ax.set_ylabel('ì‚¬ê³  ê±´ìˆ˜', fontsize=12)
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right", fontsize=10); ax.tick_params(axis='y', labelsize=10)
    ax.legend(title='ì‚¬ê³ ì›ì¸', bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=9)
    ax.grid(axis='y', linestyle='--', alpha=0.7); ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))
    plt.tight_layout(rect=[0, 0, 0.88, 1]); st.pyplot(fig)

def plot_pie_major_incident_causes(df_rescue, top_n=7):
    if df_rescue.empty or 'ì‚¬ê³ ì›ì¸' not in df_rescue.columns: st.info("ì£¼ìš” ì‚¬ê³ ì›ì¸ ë¹„ìœ¨ íŒŒì´ ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return
    cause_counts = df_rescue['ì‚¬ê³ ì›ì¸'].value_counts();
    if cause_counts.empty: st.info("ì‚¬ê³ ì›ì¸ ë°ì´í„°ê°€ ì—†ì–´ íŒŒì´ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); return
    if len(cause_counts) > top_n:
        top_causes_pie = cause_counts.nlargest(top_n).copy()
        other_sum_pie = cause_counts.nsmallest(len(cause_counts) - top_n).sum()
        if other_sum_pie > 0: top_causes_pie.loc['ê¸°íƒ€ì›ì¸'] = other_sum_pie
    else: top_causes_pie = cause_counts.copy()
    if top_causes_pie.empty: st.info("íŒŒì´ ì°¨íŠ¸ë¥¼ ìœ„í•œ ìµœì¢… ì‚¬ê³ ì›ì¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."); return
    fig, ax = plt.subplots(figsize=(10, 8))
    patches, texts, autotexts = ax.pie(top_causes_pie, labels=top_causes_pie.index, autopct='%1.1f%%', startangle=140, pctdistance=0.85, wedgeprops={'edgecolor': 'grey', 'linewidth': 0.7}) # colors ì œê±°
    for text in texts: text.set_fontsize(10)
    for autotext in autotexts: autotext.set_fontsize(9); autotext.set_color('black')
    ax.set_title(f'ì£¼ìš” ì‚¬ê³ ì›ì¸ ë¹„ìœ¨ (ìƒìœ„ {top_n}ê°œ ë° ê¸°íƒ€)', fontsize=16, pad=20); ax.axis('equal')
    plt.tight_layout(); st.pyplot(fig)

def plot_correlation_scatter_housing(merged_df, x_col, y_col, title_text):
    if merged_df.empty or x_col not in merged_df.columns or y_col not in merged_df.columns: st.info(f"'{title_text}' ì‚°ì ë„ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return
    if not pd.api.types.is_numeric_dtype(merged_df[x_col]) or not pd.api.types.is_numeric_dtype(merged_df[y_col]): st.warning(f"ì‚°ì ë„ìš© ì»¬ëŸ¼('{x_col}', '{y_col}') ì¤‘ ìˆ«ìí˜•ì´ ì•„ë‹Œ ê²ƒì´ ìˆìŠµë‹ˆë‹¤."); return
    correlation = merged_df[x_col].corr(merged_df[y_col])
    st.write(f"**ìƒê´€ê³„ìˆ˜ ({x_col} vs {y_col}): {correlation:.3f}**")
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.regplot(x=x_col, y=y_col, data=merged_df, ax=ax, color='darkcyan', scatter_kws={'s':60, 'alpha':0.65, 'edgecolor':'black'}, line_kws={'color':'red', 'linewidth':1.5})
    ax.set_title(title_text, fontsize=15); ax.set_xlabel(x_col, fontsize=12); ax.set_ylabel(y_col, fontsize=12)
    ax.grid(True, linestyle=':', alpha=0.6); ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}')); ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))
    plt.tight_layout(); st.pyplot(fig)

def plot_bubble_chart_housing(df_final_merged, target_cause_for_bubble):
    required_cols = ['ë…¸í›„ì£¼íƒìˆ˜', 'ë…¸ì¸ì¸êµ¬ìˆ˜', f'{target_cause_for_bubble}ê±´ìˆ˜', 'ë°œìƒì¥ì†Œ_êµ¬']
    if df_final_merged.empty or not all(c in df_final_merged.columns for c in required_cols): st.info(f"ë²„ë¸” ì°¨íŠ¸({target_cause_for_bubble})ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."); return
    fig, ax = plt.subplots(figsize=(12, 8))
    bubble_sizes_data = df_final_merged[f'{target_cause_for_bubble}ê±´ìˆ˜']
    min_bubble_size, max_bubble_size = 30, 1200
    if bubble_sizes_data.nunique() <= 1: scaled_bubble_sizes = pd.Series([100] * len(bubble_sizes_data), index=bubble_sizes_data.index)
    else:
        scaled_bubble_sizes = (bubble_sizes_data - bubble_sizes_data.min()) / (bubble_sizes_data.max() - bubble_sizes_data.min() + 1e-9) * (max_bubble_size - min_bubble_size) + min_bubble_size
        scaled_bubble_sizes[bubble_sizes_data == 0] = min_bubble_size / 2
    scatter_plot = ax.scatter(x='ë…¸í›„ì£¼íƒìˆ˜', y='ë…¸ì¸ì¸êµ¬ìˆ˜', s=scaled_bubble_sizes, c=df_final_merged[f'{target_cause_for_bubble}ê±´ìˆ˜'], cmap='OrRd', alpha=0.7, edgecolors='grey', linewidth=0.5, data=df_final_merged) # cmap ë³€ê²½
    top_n_districts = df_final_merged.sort_values(by=f'{target_cause_for_bubble}ê±´ìˆ˜', ascending=False).head(7)
    for _, row_data in top_n_districts.iterrows(): ax.text(row_data['ë…¸í›„ì£¼íƒìˆ˜'] * 1.01, row_data['ë…¸ì¸ì¸êµ¬ìˆ˜'] * 1.01, row_data['ë°œìƒì¥ì†Œ_êµ¬'], fontsize=9, color='black', ha='left', va='bottom')
    ax.set_title(f'ë…¸í›„ ì£¼íƒ ìˆ˜, ê³ ë ¹ ì¸êµ¬ ìˆ˜ì™€ {target_cause_for_bubble} ë°œìƒ ê±´ìˆ˜', fontsize=16, pad=15)
    ax.set_xlabel('30ë…„ ì´ìƒ ë…¸í›„ ì£¼íƒ ìˆ˜', fontsize=12); ax.set_ylabel('ê³ ë ¹ ì¸êµ¬ ìˆ˜ (65ì„¸ ì´ìƒ)', fontsize=12)
    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}')); ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))
    cbar = fig.colorbar(scatter_plot, ax=ax, label=f'{target_cause_for_bubble} ë°œìƒ ê±´ìˆ˜'); cbar.ax.tick_params(labelsize=10)
    ax.grid(True, linestyle=':', alpha=0.6); plt.tight_layout(); st.pyplot(fig)
    # ìƒê´€ê³„ìˆ˜ ê³„ì‚° ë° ì¶œë ¥ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€

# --- Streamlit í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ---
def run_housing_safety_page():
    st.title("ğŸ  ë…¸í›„ ì£¼íƒ, ê³ ë ¹ ì¸êµ¬, ì£¼ê±° ì•ˆì „ì‚¬ê³  ìƒê´€ê´€ê³„")
    set_korean_font()

    df_rescue_raw = load_csv("data/ì„œìš¸íŠ¹ë³„ì‹œ_êµ¬ì¡°í™œë™í˜„í™©.csv")
    df_elderly_raw_h = load_csv("data/ê³ ë ¹ìí˜„í™©_20250531210628.csv", header_config=[0,1,2,3])
    df_housing_raw_h = load_csv("data/ë…¸í›„ê¸°ê°„ë³„+ì£¼íƒí˜„í™©_20250601054647.csv", header_config=[0,1,2])

    if df_rescue_raw is None or df_elderly_raw_h is None or df_housing_raw_h is None:
        st.error("í•„ìˆ˜ ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'data' í´ë” ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”."); return

    df_rescue_processed = preprocess_rescue_data_cached(df_rescue_raw)
    df_elderly_processed_h = preprocess_elderly_data_for_housing_cached(df_elderly_raw_h)
    df_housing_processed_h = preprocess_housing_data_cached(df_housing_raw_h)

    if df_rescue_processed.empty or df_elderly_processed_h.empty or df_housing_processed_h.empty:
        st.error("í•„ìˆ˜ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ìœ„ì˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."); return

    st.write("### ì£¼ê±° ì•ˆì „ì‚¬ê³  í˜„í™© (2023ë…„ ë°ì´í„° ê¸°ì¤€)") # ë°ì´í„° ê¸°ì¤€ ì—°ë„ ëª…ì‹œ

    tab_titles = ["êµ¬ë³„ ì‚¬ê³  ê±´ìˆ˜", "ì‚¬ê³ ì›ì¸ ë¶„í¬ (êµ¬ë³„)", "ì£¼ìš” ì‚¬ê³ ì›ì¸ (ì „ì²´)", "ìƒê´€ê´€ê³„ ë¶„ì„", "ì¢…í•©ë¶„ì„ (ë²„ë¸”ì°¨íŠ¸)", "ì‹œê°„ëŒ€ë³„ ì‚¬ê³ "]
    tabs = st.tabs(tab_titles)

    with tabs[0]:
        st.subheader("êµ¬ë³„ ì´ ì‚¬ê³  ë°œìƒ ê±´ìˆ˜")
        plot_gu_incident_counts(df_rescue_processed)

    with tabs[1]:
        st.subheader("êµ¬ë³„ ì‚¬ê³ ì›ì¸ë³„ ë°œìƒ ê±´ìˆ˜")
        top_n_causes_stacked = st.slider("í‘œì‹œí•  ìƒìœ„ ì‚¬ê³ ì›ì¸ ê°œìˆ˜:", 3, 15, 7, key="stacked_bar_top_n_slider_housing_main")
        plot_stacked_bar_incident_causes_by_gu(df_rescue_processed, top_n_causes=top_n_causes_stacked)

    with tabs[2]:
        st.subheader("ì£¼ìš” ì‚¬ê³ ì›ì¸ ë¹„ìœ¨ (ì„œìš¸ì‹œ ì „ì²´)")
        top_n_causes_pie = st.slider("í‘œì‹œí•  ìƒìœ„ ì‚¬ê³ ì›ì¸ ê°œìˆ˜:", 3, 10, 7, key="pie_chart_top_n_slider_housing_main")
        plot_pie_major_incident_causes(df_rescue_processed, top_n=top_n_causes_pie)

    with tabs[3]:
        st.subheader("ë…¸ì¸ì¸êµ¬ ë° ë…¸í›„ì£¼íƒê³¼ì˜ ìƒê´€ê´€ê³„")
        if 'ì‚¬ê³ ì›ì¸' in df_rescue_processed.columns:
            unique_causes_list_h_corr = sorted(df_rescue_processed['ì‚¬ê³ ì›ì¸'].unique())
            default_idx_corr = unique_causes_list_h_corr.index('í™”ì¬') if 'í™”ì¬' in unique_causes_list_h_corr else 0
            selected_cause_corr = st.selectbox("ìƒê´€ê´€ê³„ ë¶„ì„ ì‚¬ê³  ì›ì¸:", unique_causes_list_h_corr, index=default_idx_corr, key="corr_cause_select_housing_main")
            if selected_cause_corr:
                cause_incidents_df = df_rescue_processed[df_rescue_processed['ì‚¬ê³ ì›ì¸'] == selected_cause_corr]['ë°œìƒì¥ì†Œ_êµ¬'].value_counts().reset_index()
                cause_incidents_df.columns = ['ë°œìƒì¥ì†Œ_êµ¬', f'{selected_cause_corr}ê±´ìˆ˜']

                merged_df_corr_elderly = pd.merge(cause_incidents_df, df_elderly_processed_h, on='ë°œìƒì¥ì†Œ_êµ¬', how='inner')
                plot_correlation_scatter_housing(merged_df_corr_elderly, 'ë…¸ì¸ì¸êµ¬ìˆ˜', f'{selected_cause_corr}ê±´ìˆ˜', f"ë…¸ì¸ ì¸êµ¬ìˆ˜ì™€ {selected_cause_corr} ë°œìƒ ê±´ìˆ˜")
                st.divider()
                merged_df_corr_housing = pd.merge(cause_incidents_df, df_housing_processed_h, on='ë°œìƒì¥ì†Œ_êµ¬', how='inner')
                plot_correlation_scatter_housing(merged_df_corr_housing, 'ë…¸í›„ì£¼íƒìˆ˜', f'{selected_cause_corr}ê±´ìˆ˜', f"ë…¸í›„ ì£¼íƒìˆ˜ì™€ {selected_cause_corr} ë°œìƒ ê±´ìˆ˜")
        else: st.info("êµ¬ì¡°í™œë™ ë°ì´í„°ì— 'ì‚¬ê³ ì›ì¸' ì»¬ëŸ¼ì´ ì—†ì–´ ìƒê´€ê´€ê³„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with tabs[4]:
        st.subheader("ì¢…í•© ë¶„ì„: ë…¸í›„ ì£¼íƒ, ê³ ë ¹ ì¸êµ¬, íŠ¹ì • ì‚¬ê³  (ë²„ë¸”ì°¨íŠ¸)")
        unique_causes_list_h_bubble = sorted(df_rescue_processed['ì‚¬ê³ ì›ì¸'].unique()) if 'ì‚¬ê³ ì›ì¸' in df_rescue_processed.columns else ['í™”ì¬']
        default_idx_bubble = unique_causes_list_h_bubble.index('í™”ì¬') if 'í™”ì¬' in unique_causes_list_h_bubble else 0
        cause_for_bubble = st.selectbox("ë²„ë¸” í¬ê¸° ê¸°ì¤€ ì‚¬ê³  ì›ì¸:", unique_causes_list_h_bubble, index=default_idx_bubble, key="bubble_cause_select_housing_main")
        if cause_for_bubble:
            df_merged_bubble_step1 = pd.merge(df_housing_processed_h, df_elderly_processed_h, on='ë°œìƒì¥ì†Œ_êµ¬', how='inner')
            safety_accidents_for_bubble = df_rescue_processed[df_rescue_processed['ì‚¬ê³ ì›ì¸'] == cause_for_bubble]['ë°œìƒì¥ì†Œ_êµ¬'].value_counts().reset_index()
            safety_accidents_for_bubble.columns = ['ë°œìƒì¥ì†Œ_êµ¬', f'{cause_for_bubble}ê±´ìˆ˜']
            df_final_merged_for_bubble = pd.merge(df_merged_bubble_step1, safety_accidents_for_bubble, on='ë°œìƒì¥ì†Œ_êµ¬', how='left')
            df_final_merged_for_bubble[f'{cause_for_bubble}ê±´ìˆ˜'] = df_final_merged_for_bubble[f'{cause_for_bubble}ê±´ìˆ˜'].fillna(0).astype(int)
            if not df_final_merged_for_bubble.empty: plot_bubble_chart_housing(df_final_merged_for_bubble, cause_for_bubble)
            else: st.info(f"'{cause_for_bubble}' ì‚¬ê³  ê¸°ì¤€ ì¢…í•© ë¶„ì„ìš© ë°ì´í„° ë³‘í•© ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    with tabs[5]:
        st.subheader("ì‹œê°„ëŒ€ë³„ ì‚¬ê³  ë°œìƒ ì¶”ì´")
        if 'ì‹ ê³ ì‹œê°' in df_rescue_processed.columns:
            df_rescue_time_analysis = df_rescue_processed.copy()
            df_rescue_time_analysis['ì‹ ê³ ì‹œê°„_dt'] = pd.to_datetime(df_rescue_time_analysis['ì‹ ê³ ì‹œê°'], format='%H:%M', errors='coerce')
            if df_rescue_time_analysis['ì‹ ê³ ì‹œê°„_dt'].isnull().sum() > len(df_rescue_time_analysis) * 0.8:
                df_rescue_time_analysis['ì‹ ê³ ì‹œê°„_dt'] = pd.to_datetime(df_rescue_time_analysis['ì‹ ê³ ì‹œê°'], format='%H:%M:%S', errors='coerce')
            if 'ì‹ ê³ ì‹œê°„_dt' in df_rescue_time_analysis.columns and not df_rescue_time_analysis['ì‹ ê³ ì‹œê°„_dt'].isnull().all():
                df_rescue_time_analysis['ì‹ ê³ ì‹œê°„(ì‹œ)'] = df_rescue_time_analysis['ì‹ ê³ ì‹œê°„_dt'].dt.hour
                hourly_incidents_counts = df_rescue_time_analysis.dropna(subset=['ì‹ ê³ ì‹œê°„(ì‹œ)'])['ì‹ ê³ ì‹œê°„(ì‹œ)'].astype(int).value_counts().sort_index()
                if not hourly_incidents_counts.empty:
                    fig_time, ax_time = plt.subplots(figsize=(12, 6))
                    sns.lineplot(x=hourly_incidents_counts.index, y=hourly_incidents_counts.values, marker='o', color='indigo', ax=ax_time)
                    ax_time.set_title('ì‹œê°„ëŒ€ë³„ ì‚¬ê³  ë°œìƒ ì¶”ì´', fontsize=15); ax_time.set_xlabel('ì‹ ê³  ì‹œê°„ (0ì‹œ ~ 23ì‹œ)', fontsize=12); ax_time.set_ylabel('ì‚¬ê³  ê±´ìˆ˜', fontsize=12)
                    ax_time.set_xticks(ticks=range(0, 24)); ax_time.grid(True, linestyle='--', alpha=0.7)
                    ax_time.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}')); plt.tight_layout(); st.pyplot(fig_time)
                else: st.info("ì‹œê°„ëŒ€ë³„ ì‚¬ê³  ë°œìƒ ì¶”ì´ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            else: st.info("êµ¬ì¡°í™œë™ ë°ì´í„°ì˜ 'ì‹ ê³ ì‹œê°'ì„ ìœ íš¨í•œ ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else: st.info("êµ¬ì¡°í™œë™ ë°ì´í„°ì— 'ì‹ ê³ ì‹œê°' ì»¬ëŸ¼ì´ ì—†ì–´ ì‹œê°„ëŒ€ë³„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    run_housing_safety_page()